## 倹 Subtopic 4.7.3: Addressing GAN Training Instabilities & Improved Techniques

**Goal:** Understand common GAN training problems like mode collapse and vanishing gradients, and explore techniques like Wasserstein GAN (WGAN) and WGAN with Gradient Penalty (WGAN-GP) designed to improve stability and sample quality.

**Resources:**

* **Original WGAN Paper:** [Arjovsky et al., 2017 - Wasserstein GAN](https://arxiv.org/abs/1701.07875)
* **WGAN-GP Paper:** [Gulrajani et al., 2017 - Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)
* **Blog Post Explaining WGAN/WGAN-GP:** [Lil'Log - WGANs](https://lilianweng.github.io/posts/2017-08-20-gan/#wasserstein-gan-wgan), [Paper Explained - WGAN-GP](https://jonathan-hui.medium.com/gan-wasserstein-gan-wgan-gp-692bf1d95378)
* **Earth Mover's Distance (Wasserstein-1 Distance):** [Wikipedia](https://en.wikipedia.org/wiki/Wasserstein_metric)

---

### 隼 **Exercise 1: Understanding Mode Collapse & Vanishing Gradients**

**Goal:** Explain the concepts of mode collapse and vanishing gradients in the context of GAN training.

**Instructions:**

1.  **Mode Collapse:**
    * Define mode collapse. What happens to the variety of samples generated by G?
    * Why might G converge to producing only a few different types of samples, even if the real data distribution is diverse? (Hint: D becomes too good at identifying specific flaws, G over-optimizes for those).
    * Provide a visual example or analogy for mode collapse (e.g., generating only one type of digit when trained on MNIST).
2.  **Vanishing Gradients (for the Generator):**
    * Explain how vanishing gradients can occur for the Generator, especially when the Discriminator becomes very accurate and confident. (Hint: Consider the `log(1 - D(G(z)))` loss when `D(G(z))` is close to 0, or `log D(G(z))` when `D(G(z))` is close to 0 for the non-saturating version).
    * How does this affect the Generator's ability to learn and improve?
3.  How do these two problems (mode collapse and vanishing gradients) often relate to each other or exacerbate one another?
4.  **Challenge:** Can the original GAN's minimax loss function theoretically lead to a stable equilibrium? What practical issues often prevent this?

---

### 隼 **Exercise 2: Wasserstein GAN (WGAN) - Critic and Loss Function**

**Goal:** Understand the key modifications introduced by WGAN: using a "Critic" instead of a Discriminator and employing the Wasserstein-1 distance (Earth Mover's Distance) as the basis for the loss.

**Instructions:**

1.  Explain the role of the **Critic** in WGAN. How does its objective differ from the original GAN's Discriminator (which outputs a probability)? What kind of values does the Critic aim to output for real vs. fake samples?
2.  The WGAN loss functions are approximately:
    * **Critic Loss (`loss_C`):** `maximize [ E_{x~P_r}[C(x)] - E_{z~P_z}[C(G(z))] ]` (or minimize its negative).
    * **Generator Loss (`loss_G`):** `maximize [ E_{z~P_z}[C(G(z))] ]` (or minimize `-E_{z~P_z}[C(G(z))]`).
3.  Implement these WGAN loss functions in Python (PyTorch/TensorFlow). The Critic `C(x)` outputs a raw scalar score (no sigmoid).
4.  What is the primary motivation for using the Wasserstein distance? How does it provide more meaningful gradients even when the distributions of real and fake data have little overlap (unlike Jensen-Shannon divergence used implicitly by original GANs)?
5.  **Challenge:** The WGAN paper requires the Critic to be a 1-Lipschitz function. What does this mean intuitively, and why is it important for approximating the Wasserstein distance?

---

### 隼 **Exercise 3: WGAN with Weight Clipping**

**Goal:** Implement weight clipping as proposed in the original WGAN paper to enforce the Lipschitz constraint on the Critic.

**Instructions:**

1.  Start with a DCGAN-like architecture for your Generator and Critic (remember the Critic does *not* have a final sigmoid).
2.  In your WGAN training loop, after each Critic update (`optimizer_C.step()`):
    * Iterate through all parameters (weights) of the Critic network.
    * Clip each weight to a small fixed range (e.g., `[-0.01, 0.01]`) using `param.data.clamp_(-0.01, 0.01)` in PyTorch or equivalent in TensorFlow.
3.  Train this WGAN with weight clipping on a simple image dataset. Monitor the Critic's loss, Generator's loss, and the quality of generated samples.
4.  Discuss the potential problems associated with weight clipping:
    * Can it lead to capacity underuse in the Critic (weights pushed to the extremes of the clipping range)?
    * Can it lead to vanishing or exploding gradients if the clipping range is chosen poorly?
5.  **Challenge:** Observe the distribution of weights in your Critic during training with weight clipping. Do many weights congregate at the `+c` and `-c` boundaries?

---

### 隼 **Exercise 4: WGAN with Gradient Penalty (WGAN-GP)**

**Goal:** Implement the Gradient Penalty term from WGAN-GP as an alternative to weight clipping for enforcing the Lipschitz constraint.

**Instructions:**

1.  Start with your WGAN setup (DCGAN-like G and C, WGAN losses from Exercise 2). **Remove weight clipping.**
2.  **Gradient Penalty Calculation:**
    * For each Critic update, sample real data `x_real` and generate fake data `x_fake = G(z)`.
    * Create interpolated samples `x_interp` along straight lines between pairs of real and fake samples:
        * `epsilon = random_uniform_sample(shape=[batch_size, 1, 1, 1])` (between 0 and 1)
        * `x_interp = epsilon * x_real + (1 - epsilon) * x_fake`
    * Get the Critic's output for these interpolated samples: `C_interp_outputs = C(x_interp)`.
    * Calculate the gradients of `C_interp_outputs` with respect to `x_interp`. (Requires `x_interp` to track gradients).
    * Calculate the L2 norm of these gradients for each interpolated sample.
    * The gradient penalty is `lambda_gp * E_x_interp[ (gradient_norm - 1)^2 ]`. `lambda_gp` is a hyperparameter (e.g., 10).
3.  Add this gradient penalty term to your Critic's loss: `loss_C_total = loss_C_original + gradient_penalty`.
4.  Implement this gradient penalty calculation in your PyTorch/TensorFlow training loop. Ensure gradients are enabled for `x_interp` when passing it to the Critic for the penalty calculation.
5.  Train your WGAN-GP. Compare its training stability and sample quality to the WGAN with weight clipping (Exercise 3) and potentially to the original DCGAN.
6.  Why is enforcing the Lipschitz constraint via gradient penalty generally preferred over weight clipping?
7.  **Challenge:** Explain the intuition behind penalizing the deviation of the gradient norm from 1 for interpolated samples. How does this encourage the Critic to have gradients with norm 1 (a property of 1-Lipschitz functions) along these interpolations?

---

### 隼 **Exercise 5: Comparing GAN, WGAN, and WGAN-GP**

**Goal:** Conduct a comparative experiment training a standard GAN, WGAN (with clipping), and WGAN-GP on the same dataset and architecture to observe differences in training stability and sample quality.

**Instructions:**

1.  Choose a dataset (e.g., CIFAR-10, CelebA subset) and a fixed DCGAN-like architecture for G and D/C.
2.  Implement three training setups:
    * **GAN:** Original minimax loss (or non-saturating G loss), D with sigmoid.
    * **WGAN:** WGAN loss, C without sigmoid, weight clipping for C.
    * **WGAN-GP:** WGAN loss, C without sigmoid, gradient penalty for C.
3.  Use similar optimizers and learning rates (though WGAN often benefits from RMSProp or smaller learning rates for Adam compared to original GANs). Train for the same number of epochs.
4.  During training, monitor:
    * G loss and D/C loss curves.
    * Periodically save generated samples from a fixed latent vector.
5.  After training, qualitatively compare the generated samples from each method.
6.  Compare the stability of the loss curves. Did WGAN or WGAN-GP show more stable training (e.g., less mode collapse, smoother D/C loss)?
7.  Discuss your findings. Which method was easiest to train? Which produced the best visual results?
8.  **Challenge:** If possible, calculate a simple quantitative metric for diversity/quality (e.g., if trained on MNIST, use a pre-trained MNIST classifier to assess the "realism" and diversity of generated digits). This is a precursor to FID/IS from a later subtopic.
